{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import opensfm\n",
    "import cv2\n",
    "from opensfm import dataset, features, io\n",
    "import json\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/ubuntu/projects/OpenSfM/data/gezer/'\n",
    "data = dataset.DataSet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v2 dji fc300s 4000 3000 perspective 0.5555': PerspectiveCamera('v2 dji fc300s 4000 3000 perspective 0.5555', 'perspective', 4000, 3000, 0.5555555555555556, 0.0, 0.0, 0.5555555555555556, 0.0, 0.0)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera = data.load_camera_models(); camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_name = list(camera.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PerspectiveCamera('v2 dji fc300s 4000 3000 perspective 0.5555', 'perspective', 4000, 3000, 0.5555555555555556, 0.0, 0.0, 0.5555555555555556, 0.0, 0.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera = camera[camera_name]; camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.22222222e+03, 0.00000000e+00, 1.99950000e+03],\n",
       "       [0.00000000e+00, 2.22222222e+03, 1.49950000e+03],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = camera.get_K_in_pixel_coordinates(); K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notes: normalize_pts as defined in /home/ubuntu/projects/OpenSfM/opensfm/features.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGRansac:\n",
    "    \n",
    "    # init model with default params. Calculate only fundamental matrix\n",
    "    def __init__(self,\n",
    "                 frame_size,                 \n",
    "                 batchsize=32,\n",
    "#                  fmat=True,\n",
    "                 hyps=1000,\n",
    "                 model='',\n",
    "                 nfeatures=2000,\n",
    "                 nosideinfo=False,                 \n",
    "                 orb=False,\n",
    "                 ratio=1.0,\n",
    "                 refine=False,\n",
    "                 resblocks=12,\n",
    "                 rootsift=False,\n",
    "                 session='',\n",
    "                 thershold=0.001):\n",
    "        \n",
    "        # load network\n",
    "        model_file = model\n",
    "        if len(model_file) == 0:\n",
    "            model_file = util.create_session_string('e2e', fmat, orb, rootsift, ratio, session)\n",
    "            model_file = 'models/weights_' + model_file + '.net'            \n",
    "            print('Loading pre-trained model:', model_file)\n",
    "            \n",
    "        model = CNNet(resblocks)\n",
    "        model.load_state_dict(torch.load(model_file))\n",
    "        model = model.cuda()\n",
    "        model.eval()        \n",
    "        print('model ', model_file, ' successfully loaded.')        \n",
    "        \n",
    "        self.model      = model\n",
    "        self.frame_size = frame_size\n",
    "        self.nosideinfo = nosideinfo\n",
    "        self.hyps       = hyps\n",
    "        self.threshold  = threshold\n",
    "        self.refine     = refine\n",
    "        \n",
    "    \n",
    "    # pts1 and pts2 must be normalized to the frame size before running the procedure below\n",
    "    # as well the ratios must be computed\n",
    "    def findFundamentalMat(self, pts1, pts2, ratios):\n",
    "        \n",
    "        # normalize x and y coordinates before passing them to the network\n",
    "        # normalized by the image size\n",
    "        util.normalize_pts(pts1, self.frame_size)\n",
    "        util.normalize_pts(pts2, self.frame_size)\n",
    "        \n",
    "        if self.nosideinfo:\n",
    "            # remove side information before passing it to the network\n",
    "            ratios = np.zeros(ratios.shape)\n",
    "        \n",
    "        # create data tensor of feature coordinates and matching ratios\n",
    "        correspondences = np.concatenate((pts1, pts2, ratios), axis=2)\n",
    "        correspondences = np.transpose(correspondences)\n",
    "        correspondences = torch.from_numpy(correspondences).float()\n",
    "\n",
    "        # predict neural guidance, i.e. RANSAC sampling probabilities\n",
    "        log_probs = self.model(correspondences.unsqueeze(0).cuda())[0] #zero-indexing creates and removes a dummy batch dimension\n",
    "        probs = torch.exp(log_probs).cpu()\n",
    "\n",
    "        out_model     = torch.zeros((3, 3)).float() # estimated model\n",
    "        out_inliers   = torch.zeros(log_probs.size()) # inlier mask of estimated model\n",
    "        out_gradients = torch.zeros(log_probs.size()) # gradient tensor (only used during training)\n",
    "        rand_seed     = 0 # random seed to by used in C++\n",
    "        \n",
    "        # run NG-RANSAC\n",
    "        # === CASE FUNDAMENTAL MATRIX =========================================\n",
    "\n",
    "        # undo normalization of x and y image coordinates\n",
    "        util.denormalize_pts(correspondences[0:2], self.frame_size)\n",
    "        util.denormalize_pts(correspondences[2:4], self.frame_size)\n",
    "        \n",
    "        incount = ngransac.find_fundamental_mat(correspondences, \n",
    "                                                probs, \n",
    "                                                rand_seed, \n",
    "                                                self.hyps, \n",
    "                                                self.threshold, \n",
    "                                                self.refine, \n",
    "                                                out_model, \n",
    "                                                out_inliers, \n",
    "                                                out_gradients)\n",
    "        \n",
    "        print(\"\\n=== Model found by NG-RANSAC: =======\\n\")\n",
    "        print(\"\\nNG-RANSAC Inliers: \", int(incount))\n",
    "        \n",
    "        # Fundamental matrix\n",
    "        return out_model.numpy()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
